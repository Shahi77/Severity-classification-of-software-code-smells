{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf1MTNDhw3H7fpM/SrgosH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahi77/Severity-classification-of-software-code-smells/blob/main/Brain_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#1. LOADING & PRE-PROCESSING CLASS-LEVEL DATASET\n",
        "df = pd.read_csv('class.csv', low_memory=False)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcKJCbw-F3ld",
        "outputId": "8de6cc7f-011d-4db6-b453-d004eefcfbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 373400 entries, 0 to 373399\n",
            "Data columns (total 50 columns):\n",
            " #   Column                    Non-Null Count   Dtype  \n",
            "---  ------                    --------------   -----  \n",
            " 0   Address                   373400 non-null  object \n",
            " 1   Brain Class               373400 non-null  bool   \n",
            " 2   Data Class                373400 non-null  bool   \n",
            " 3   Futile Abstract Pipeline  373400 non-null  bool   \n",
            " 4   Futile Hierarchy          373400 non-null  bool   \n",
            " 5   God Class                 373400 non-null  bool   \n",
            " 6   Hierarchy Duplication     373400 non-null  bool   \n",
            " 7   Model Class               373400 non-null  bool   \n",
            " 8   Schizofrenic Class        373400 non-null  bool   \n",
            " 9   ABUSEINH                  373400 non-null  int64  \n",
            " 10  AMW                       373400 non-null  float64\n",
            " 11  ATFD                      373400 non-null  int64  \n",
            " 12  BOvM                      373400 non-null  int64  \n",
            " 13  BUR                       373400 non-null  float64\n",
            " 14  CBO                       373400 non-null  int64  \n",
            " 15  CC                        373400 non-null  int64  \n",
            " 16  CM                        373400 non-null  int64  \n",
            " 17  CRIX                      373400 non-null  float64\n",
            " 18  DAC                       373400 non-null  int64  \n",
            " 19  DIT                       373400 non-null  int64  \n",
            " 20  EDUPCLS                   373400 non-null  int64  \n",
            " 21  FANOUT                    373400 non-null  int64  \n",
            " 22  FDP                       373400 non-null  int64  \n",
            " 23  GREEDY                    373400 non-null  int64  \n",
            " 24  HDUPCLS                   373400 non-null  int64  \n",
            " 25  HIT                       373400 non-null  int64  \n",
            " 26  IDUPLINES                 373400 non-null  int64  \n",
            " 27  LOCC                      373400 non-null  int64  \n",
            " 28  NAS                       373400 non-null  int64  \n",
            " 29  NAbsM                     373400 non-null  int64  \n",
            " 30  NDU                       373400 non-null  int64  \n",
            " 31  NOA                       373400 non-null  int64  \n",
            " 32  NOAM                      373400 non-null  int64  \n",
            " 33  NOD                       373400 non-null  int64  \n",
            " 34  NODD                      373400 non-null  int64  \n",
            " 35  NOM                       373400 non-null  int64  \n",
            " 36  NOPA                      373400 non-null  int64  \n",
            " 37  NProtM                    373400 non-null  int64  \n",
            " 38  NSPECM                    373400 non-null  int64  \n",
            " 39  NTempF                    373400 non-null  int64  \n",
            " 40  NrBM                      373400 non-null  int64  \n",
            " 41  NrEC                      373400 non-null  int64  \n",
            " 42  NrFE                      373400 non-null  int64  \n",
            " 43  NrIC                      373400 non-null  int64  \n",
            " 44  NrSS                      373400 non-null  int64  \n",
            " 45  PNAS                      373400 non-null  float64\n",
            " 46  SCHIZO                    373400 non-null  int64  \n",
            " 47  TCC                       373400 non-null  float64\n",
            " 48  WMC                       373400 non-null  int64  \n",
            " 49  WOC                       373400 non-null  float64\n",
            "dtypes: bool(8), float64(6), int64(35), object(1)\n",
            "memory usage: 122.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime\n",
        "import seaborn as sns\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%config InlineBackend.figure_format='retina'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from operator import itemgetter\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost.sklearn import XGBClassifier as GBC\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.ensemble\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "\n",
        "# from xgboost import XGBClassifier\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "train_df = pd.read_csv('class.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pAfExxJX03q",
        "outputId": "e24750ca-b0bc-40a6-b902-e7238b581c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=979d1bfe29c9adaeb1a93ae8a0ff538ae64a7ca188ccd43b0b5f256a9cf0b3b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('class.csv', header=0)\n",
        "test_df = pd.read_csv('class.csv', header=0)\n",
        "cols=train_df.columns"
      ],
      "metadata": {
        "id": "eKszOjLtYBO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['source']='train'\n",
        "test_df['source']='test'\n",
        "data = pd.concat([train_df, test_df],ignore_index=True)\n",
        "print (train_df.shape, test_df.shape, data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icPFUGLBYH32",
        "outputId": "9a72d299-89a8-4b8e-892a-f6a93f92a0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(373400, 51) (373400, 51) (746800, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide into test and train:\n",
        "train_df = data.loc[data['source']==\"train\"]\n",
        "test_df = data.loc[data['source']==\"test\"]\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "LqxfbwI-YL4b",
        "outputId": "3d7ce025-ed9c-4766-9545-6f40747284ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Address  Brain Class  Data Class  \\\n",
              "0  org.apache.hadoop.metrics2.sink.SqlServerSinkTest        False       False   \n",
              "1   org.apache.ambari.TestMapReduceJobHistoryUpdater        False       False   \n",
              "2  org.apache.ambari.log4j.hadoop.mapreduce.jobhi...        False       False   \n",
              "3  org.apache.ambari.log4j.hadoop.mapreduce.jobhi...        False       False   \n",
              "4  org.apache.ambari.log4j.hadoop.mapreduce.jobhi...        False       False   \n",
              "\n",
              "   Futile Abstract Pipeline  Futile Hierarchy  God Class  \\\n",
              "0                     False             False      False   \n",
              "1                     False             False      False   \n",
              "2                     False             False      False   \n",
              "3                     False             False      False   \n",
              "4                     False             False      False   \n",
              "\n",
              "   Hierarchy Duplication  Model Class  Schizofrenic Class  ABUSEINH  ...  \\\n",
              "0                  False         True               False         0  ...   \n",
              "1                  False         True               False         0  ...   \n",
              "2                  False         True               False         0  ...   \n",
              "3                  False         True               False         0  ...   \n",
              "4                  False         True                True         0  ...   \n",
              "\n",
              "   NrEC  NrFE  NrIC  NrSS  PNAS  SCHIZO   TCC  WMC  WOC  source  \n",
              "0     0     0     0     0 -1.00       0  0.14    7  1.0   train  \n",
              "1     0     0     0     0 -1.00       0  0.00    5  1.0   train  \n",
              "2     0     0     0     0  0.00       0  0.00    2  1.0   train  \n",
              "3     0     3     1     0  0.67       0  0.37   73  1.0   train  \n",
              "4     0     0     0     0  0.00       2  0.00    3  1.0   train  \n",
              "\n",
              "[5 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57aa5792-d7be-4c7a-9858-3cc364f6d107\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Address</th>\n",
              "      <th>Brain Class</th>\n",
              "      <th>Data Class</th>\n",
              "      <th>Futile Abstract Pipeline</th>\n",
              "      <th>Futile Hierarchy</th>\n",
              "      <th>God Class</th>\n",
              "      <th>Hierarchy Duplication</th>\n",
              "      <th>Model Class</th>\n",
              "      <th>Schizofrenic Class</th>\n",
              "      <th>ABUSEINH</th>\n",
              "      <th>...</th>\n",
              "      <th>NrEC</th>\n",
              "      <th>NrFE</th>\n",
              "      <th>NrIC</th>\n",
              "      <th>NrSS</th>\n",
              "      <th>PNAS</th>\n",
              "      <th>SCHIZO</th>\n",
              "      <th>TCC</th>\n",
              "      <th>WMC</th>\n",
              "      <th>WOC</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>org.apache.hadoop.metrics2.sink.SqlServerSinkTest</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>org.apache.ambari.TestMapReduceJobHistoryUpdater</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>org.apache.ambari.log4j.hadoop.mapreduce.jobhi...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>org.apache.ambari.log4j.hadoop.mapreduce.jobhi...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0</td>\n",
              "      <td>0.37</td>\n",
              "      <td>73</td>\n",
              "      <td>1.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>org.apache.ambari.log4j.hadoop.mapreduce.jobhi...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 51 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57aa5792-d7be-4c7a-9858-3cc364f6d107')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57aa5792-d7be-4c7a-9858-3cc364f6d107 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57aa5792-d7be-4c7a-9858-3cc364f6d107');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f493355d-95e1-4234-a648-2323932a4efb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f493355d-95e1-4234-a648-2323932a4efb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f493355d-95e1-4234-a648-2323932a4efb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, roc_auc_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import lightgbm as lgb\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
        "from imblearn.pipeline import make_pipeline\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class BrainClassDetector:\n",
        "    def __init__(self):\n",
        "        self.results = pd.DataFrame(columns=['Code_smell', 'Algo', 'Balance', 'Ratio',\n",
        "                                             'Accuracy', 'Precision', 'F1_score', 'AUC'])\n",
        "        self.oversamplers = {\n",
        "            'RandomOverSampler': RandomOverSampler(sampling_strategy=1, random_state=42),\n",
        "            'SMOTE': SMOTE(sampling_strategy=1, random_state=42),\n",
        "            'BorderlineSMOTE': BorderlineSMOTE(sampling_strategy=1, random_state=42),\n",
        "            'SVMSMOTE': SVMSMOTE(sampling_strategy=1, random_state=42),\n",
        "            'ADASYN': ADASYN(sampling_strategy=1, random_state=42)\n",
        "        }\n",
        "\n",
        "    def load_data(self, filepath):\n",
        "        \"\"\"Load and preprocess the dataset\"\"\"\n",
        "        self.df = pd.read_csv(filepath)\n",
        "        self.features = list(self.df.select_dtypes(include=['int64', 'float64']).columns)\n",
        "        self.target = 'Brain Class'\n",
        "\n",
        "        # Convert target to integer type\n",
        "        self.df[self.target] = self.df[self.target].astype(int)\n",
        "\n",
        "        # Print dataset info\n",
        "        print(\"\\nDataset Info:\")\n",
        "        print(self.df.info())\n",
        "\n",
        "        # Check for missing values\n",
        "        missing = self.df.isnull().sum()\n",
        "        if missing.sum() > 0:\n",
        "            print(\"\\nMissing Values Found:\")\n",
        "            print(missing[missing > 0])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Prepare train, validation, and test sets\"\"\"\n",
        "        X = self.df[self.features]\n",
        "        y = self.df[self.target]\n",
        "\n",
        "        # Split data into train+val (80%) and test (20%)\n",
        "        X_temp, self.X_test, y_temp, self.y_test = train_test_split(\n",
        "            X, y, test_size=0.2, stratify=y, random_state=42\n",
        "        )\n",
        "\n",
        "        # Split train+val into train (75%) and val (25%)\n",
        "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
        "        )\n",
        "\n",
        "        # Class imbalance handling (undersampling)\n",
        "        class_counts = self.y_train.value_counts()\n",
        "        min_class = class_counts.idxmin()\n",
        "        max_class = class_counts.idxmax()\n",
        "\n",
        "        # Define different balance ratios\n",
        "        ratios = {'80_20': 0.25, '75_25': 0.33, '60_40': 0.67}\n",
        "        self.balanced_sets = {}\n",
        "\n",
        "        for name, ratio in ratios.items():\n",
        "            minority_samples = self.X_train[self.y_train == min_class]\n",
        "            majority_samples = self.X_train[self.y_train == max_class]\n",
        "\n",
        "            # Compute the number of majority class samples to keep\n",
        "            n_majority = int(len(minority_samples) / ratio)\n",
        "            selected_majority = majority_samples.sample(n=n_majority, random_state=42)\n",
        "\n",
        "            # Combine minority and majority samples\n",
        "            X_balanced = pd.concat([minority_samples, selected_majority])\n",
        "            y_balanced = pd.concat([\n",
        "                pd.Series([min_class] * len(minority_samples)),\n",
        "                pd.Series([max_class] * len(selected_majority))\n",
        "            ])\n",
        "\n",
        "            self.balanced_sets[name] = (X_balanced, y_balanced)\n",
        "\n",
        "    def evaluate_model(self, model, X_train, y_train, X_test, y_test, algo_name, balance_type, ratio):\n",
        "        \"\"\"Train and evaluate a model\"\"\"\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
        "\n",
        "        metrics = {\n",
        "            'Code_smell': self.target,\n",
        "            'Algo': algo_name,\n",
        "            'Balance': balance_type,\n",
        "            'Ratio': ratio,\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            'Precision': precision_score(y_test, y_pred),\n",
        "            'F1_score': f1_score(y_test, y_pred),\n",
        "            'AUC': roc_auc_score(y_test, y_prob)\n",
        "        }\n",
        "\n",
        "        self.results = pd.concat([self.results, pd.DataFrame([metrics])], ignore_index=True)\n",
        "\n",
        "        # Print the classification report\n",
        "        print(f\"\\nResults for {algo_name} - {balance_type} - {ratio}\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "    def train_all_models(self):\n",
        "        \"\"\"Train and evaluate models with different data sampling strategies\"\"\"\n",
        "        models = {\n",
        "            'RFC': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
        "            'KNN': KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
        "            'LLR': LogisticRegression(C=0.0001, random_state=42),\n",
        "            'SVM': CalibratedClassifierCV(LinearSVC(random_state=42))\n",
        "        }\n",
        "\n",
        "        for algo_name, model in models.items():\n",
        "            # Original imbalanced dataset\n",
        "            self.evaluate_model(\n",
        "                model, self.X_train, self.y_train, self.X_test, self.y_test, algo_name, 'None', '*'\n",
        "            )\n",
        "\n",
        "            # Undersampled datasets\n",
        "            for ratio, (X_balanced, y_balanced) in self.balanced_sets.items():\n",
        "                self.evaluate_model(\n",
        "                    model, X_balanced, y_balanced, self.X_test, self.y_test, algo_name, 'undersample', ratio\n",
        "                )\n",
        "\n",
        "            # Oversampled datasets\n",
        "            for sampler_name, sampler in self.oversamplers.items():\n",
        "                pipeline = make_pipeline(sampler, model)\n",
        "                self.evaluate_model(\n",
        "                    pipeline, self.X_train, self.y_train, self.X_test, self.y_test, algo_name, 'oversample', sampler_name\n",
        "                )\n",
        "\n",
        "    def save_results(self, filename):\n",
        "        \"\"\"Save results to a CSV file\"\"\"\n",
        "        self.results.to_csv(filename, index=False)\n",
        "        print(f\"\\nResults saved to {filename}\")\n",
        "\n",
        "# Usage\n",
        "def main():\n",
        "    detector = BrainClassDetector()\n",
        "\n",
        "    # Load dataset\n",
        "    detector.load_data('class.csv')  # Ensure the file exists in the correct path\n",
        "\n",
        "    # Prepare data\n",
        "    detector.prepare_data()\n",
        "\n",
        "    # Train and evaluate models\n",
        "    detector.train_all_models()\n",
        "\n",
        "    # Save results\n",
        "    detector.save_results('brain_class_detection_results.csv')\n",
        "\n",
        "    # Print best models based on F1 score\n",
        "    print(\"\\nBest performing models by F1 score:\")\n",
        "    best_results = detector.results.sort_values('F1_score', ascending=False).head()\n",
        "    print(best_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzN4yqbqSRv6",
        "outputId": "57a0fdd8-3890-48ea-b624-71893dcc4403"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 373400 entries, 0 to 373399\n",
            "Data columns (total 50 columns):\n",
            " #   Column                    Non-Null Count   Dtype  \n",
            "---  ------                    --------------   -----  \n",
            " 0   Address                   373400 non-null  object \n",
            " 1   Brain Class               373400 non-null  int64  \n",
            " 2   Data Class                373400 non-null  bool   \n",
            " 3   Futile Abstract Pipeline  373400 non-null  bool   \n",
            " 4   Futile Hierarchy          373400 non-null  bool   \n",
            " 5   God Class                 373400 non-null  bool   \n",
            " 6   Hierarchy Duplication     373400 non-null  bool   \n",
            " 7   Model Class               373400 non-null  bool   \n",
            " 8   Schizofrenic Class        373400 non-null  bool   \n",
            " 9   ABUSEINH                  373400 non-null  int64  \n",
            " 10  AMW                       373400 non-null  float64\n",
            " 11  ATFD                      373400 non-null  int64  \n",
            " 12  BOvM                      373400 non-null  int64  \n",
            " 13  BUR                       373400 non-null  float64\n",
            " 14  CBO                       373400 non-null  int64  \n",
            " 15  CC                        373400 non-null  int64  \n",
            " 16  CM                        373400 non-null  int64  \n",
            " 17  CRIX                      373400 non-null  float64\n",
            " 18  DAC                       373400 non-null  int64  \n",
            " 19  DIT                       373400 non-null  int64  \n",
            " 20  EDUPCLS                   373400 non-null  int64  \n",
            " 21  FANOUT                    373400 non-null  int64  \n",
            " 22  FDP                       373400 non-null  int64  \n",
            " 23  GREEDY                    373400 non-null  int64  \n",
            " 24  HDUPCLS                   373400 non-null  int64  \n",
            " 25  HIT                       373400 non-null  int64  \n",
            " 26  IDUPLINES                 373400 non-null  int64  \n",
            " 27  LOCC                      373400 non-null  int64  \n",
            " 28  NAS                       373400 non-null  int64  \n",
            " 29  NAbsM                     373400 non-null  int64  \n",
            " 30  NDU                       373400 non-null  int64  \n",
            " 31  NOA                       373400 non-null  int64  \n",
            " 32  NOAM                      373400 non-null  int64  \n",
            " 33  NOD                       373400 non-null  int64  \n",
            " 34  NODD                      373400 non-null  int64  \n",
            " 35  NOM                       373400 non-null  int64  \n",
            " 36  NOPA                      373400 non-null  int64  \n",
            " 37  NProtM                    373400 non-null  int64  \n",
            " 38  NSPECM                    373400 non-null  int64  \n",
            " 39  NTempF                    373400 non-null  int64  \n",
            " 40  NrBM                      373400 non-null  int64  \n",
            " 41  NrEC                      373400 non-null  int64  \n",
            " 42  NrFE                      373400 non-null  int64  \n",
            " 43  NrIC                      373400 non-null  int64  \n",
            " 44  NrSS                      373400 non-null  int64  \n",
            " 45  PNAS                      373400 non-null  float64\n",
            " 46  SCHIZO                    373400 non-null  int64  \n",
            " 47  TCC                       373400 non-null  float64\n",
            " 48  WMC                       373400 non-null  int64  \n",
            " 49  WOC                       373400 non-null  float64\n",
            "dtypes: bool(7), float64(6), int64(36), object(1)\n",
            "memory usage: 125.0+ MB\n",
            "None\n",
            "\n",
            "Results for RFC - None - *\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     74511\n",
            "           1       1.00      0.43      0.60       169\n",
            "\n",
            "    accuracy                           1.00     74680\n",
            "   macro avg       1.00      0.72      0.80     74680\n",
            "weighted avg       1.00      1.00      1.00     74680\n",
            "\n",
            "\n",
            "Results for RFC - undersample - 80_20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.27      1.00      0.43       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.64      1.00      0.71     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for RFC - undersample - 75_25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.26      1.00      0.41       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.63      1.00      0.70     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for RFC - undersample - 60_40\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.22      1.00      0.36       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.61      1.00      0.68     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for RFC - oversample - RandomOverSampler\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.29      1.00      0.45       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.65      1.00      0.73     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for RFC - oversample - SMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.30      1.00      0.46       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.65      1.00      0.73     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for RFC - oversample - BorderlineSMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.30      1.00      0.46       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.65      1.00      0.73     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for RFC - oversample - SVMSMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.25      1.00      0.40       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.63      1.00      0.70     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for RFC - oversample - ADASYN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.28      1.00      0.43       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.64      1.00      0.71     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for KNN - None - *\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     74511\n",
            "           1       0.45      0.17      0.24       169\n",
            "\n",
            "    accuracy                           1.00     74680\n",
            "   macro avg       0.72      0.58      0.62     74680\n",
            "weighted avg       1.00      1.00      1.00     74680\n",
            "\n",
            "\n",
            "Results for KNN - undersample - 80_20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     74511\n",
            "           1       0.08      0.98      0.14       169\n",
            "\n",
            "    accuracy                           0.97     74680\n",
            "   macro avg       0.54      0.98      0.56     74680\n",
            "weighted avg       1.00      0.97      0.98     74680\n",
            "\n",
            "\n",
            "Results for KNN - undersample - 75_25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     74511\n",
            "           1       0.07      0.98      0.13       169\n",
            "\n",
            "    accuracy                           0.97     74680\n",
            "   macro avg       0.53      0.98      0.56     74680\n",
            "weighted avg       1.00      0.97      0.98     74680\n",
            "\n",
            "\n",
            "Results for KNN - undersample - 60_40\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     74511\n",
            "           1       0.05      1.00      0.10       169\n",
            "\n",
            "    accuracy                           0.96     74680\n",
            "   macro avg       0.53      0.98      0.54     74680\n",
            "weighted avg       1.00      0.96      0.98     74680\n",
            "\n",
            "\n",
            "Results for KNN - oversample - RandomOverSampler\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     74511\n",
            "           1       0.25      0.49      0.33       169\n",
            "\n",
            "    accuracy                           1.00     74680\n",
            "   macro avg       0.62      0.74      0.66     74680\n",
            "weighted avg       1.00      1.00      1.00     74680\n",
            "\n",
            "\n",
            "Results for KNN - oversample - SMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.19      0.78      0.31       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.60      0.88      0.65     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for KNN - oversample - BorderlineSMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.21      0.66      0.32       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.60      0.83      0.66     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for KNN - oversample - SVMSMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.21      0.66      0.32       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.60      0.83      0.66     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for KNN - oversample - ADASYN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.19      0.77      0.31       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.60      0.88      0.65     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for LLR - None - *\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     74511\n",
            "           1       0.40      0.09      0.15       169\n",
            "\n",
            "    accuracy                           1.00     74680\n",
            "   macro avg       0.70      0.55      0.58     74680\n",
            "weighted avg       1.00      1.00      1.00     74680\n",
            "\n",
            "\n",
            "Results for LLR - undersample - 80_20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     74511\n",
            "           1       0.08      0.93      0.14       169\n",
            "\n",
            "    accuracy                           0.97     74680\n",
            "   macro avg       0.54      0.95      0.56     74680\n",
            "weighted avg       1.00      0.97      0.98     74680\n",
            "\n",
            "\n",
            "Results for LLR - undersample - 75_25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     74511\n",
            "           1       0.07      0.94      0.13       169\n",
            "\n",
            "    accuracy                           0.97     74680\n",
            "   macro avg       0.53      0.96      0.56     74680\n",
            "weighted avg       1.00      0.97      0.98     74680\n",
            "\n",
            "\n",
            "Results for LLR - undersample - 60_40\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     74511\n",
            "           1       0.07      0.97      0.13       169\n",
            "\n",
            "    accuracy                           0.97     74680\n",
            "   macro avg       0.54      0.97      0.56     74680\n",
            "weighted avg       1.00      0.97      0.98     74680\n",
            "\n",
            "\n",
            "Results for LLR - oversample - RandomOverSampler\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     74511\n",
            "           1       0.05      0.97      0.10       169\n",
            "\n",
            "    accuracy                           0.96     74680\n",
            "   macro avg       0.53      0.97      0.54     74680\n",
            "weighted avg       1.00      0.96      0.98     74680\n",
            "\n",
            "\n",
            "Results for LLR - oversample - SMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     74511\n",
            "           1       0.09      0.95      0.16       169\n",
            "\n",
            "    accuracy                           0.98     74680\n",
            "   macro avg       0.54      0.96      0.57     74680\n",
            "weighted avg       1.00      0.98      0.99     74680\n",
            "\n",
            "\n",
            "Results for LLR - oversample - BorderlineSMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     74511\n",
            "           1       0.08      0.94      0.14       169\n",
            "\n",
            "    accuracy                           0.97     74680\n",
            "   macro avg       0.54      0.96      0.56     74680\n",
            "weighted avg       1.00      0.97      0.99     74680\n",
            "\n",
            "\n",
            "Results for LLR - oversample - SVMSMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     74511\n",
            "           1       0.08      0.93      0.15       169\n",
            "\n",
            "    accuracy                           0.98     74680\n",
            "   macro avg       0.54      0.95      0.57     74680\n",
            "weighted avg       1.00      0.98      0.99     74680\n",
            "\n",
            "\n",
            "Results for LLR - oversample - ADASYN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     74511\n",
            "           1       0.07      0.96      0.14       169\n",
            "\n",
            "    accuracy                           0.97     74680\n",
            "   macro avg       0.54      0.97      0.56     74680\n",
            "weighted avg       1.00      0.97      0.98     74680\n",
            "\n",
            "\n",
            "Results for SVM - None - *\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     74511\n",
            "           1       0.59      0.24      0.34       169\n",
            "\n",
            "    accuracy                           1.00     74680\n",
            "   macro avg       0.80      0.62      0.67     74680\n",
            "weighted avg       1.00      1.00      1.00     74680\n",
            "\n",
            "\n",
            "Results for SVM - undersample - 80_20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.24      0.99      0.39       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.62      0.99      0.69     74680\n",
            "weighted avg       1.00      0.99      1.00     74680\n",
            "\n",
            "\n",
            "Results for SVM - undersample - 75_25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.23      0.99      0.38       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.62      0.99      0.69     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for SVM - undersample - 60_40\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     74511\n",
            "           1       0.18      0.99      0.31       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.59      0.99      0.65     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for SVM - oversample - RandomOverSampler\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.22      1.00      0.36       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.61      1.00      0.68     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for SVM - oversample - SMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.24      0.98      0.38       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.62      0.98      0.69     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for SVM - oversample - BorderlineSMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.23      0.98      0.38       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.62      0.99      0.69     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for SVM - oversample - SVMSMOTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.22      0.98      0.36       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.61      0.99      0.68     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results for SVM - oversample - ADASYN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     74511\n",
            "           1       0.23      0.98      0.37       169\n",
            "\n",
            "    accuracy                           0.99     74680\n",
            "   macro avg       0.61      0.98      0.68     74680\n",
            "weighted avg       1.00      0.99      0.99     74680\n",
            "\n",
            "\n",
            "Results saved to brain_class_detection_results.csv\n",
            "\n",
            "Best performing models by F1 score:\n",
            "    Code_smell Algo     Balance              Ratio  Accuracy  Precision  \\\n",
            "0  Brain Class  RFC        None                  *  0.998715   1.000000   \n",
            "6  Brain Class  RFC  oversample    BorderlineSMOTE  0.994764   0.301786   \n",
            "5  Brain Class  RFC  oversample              SMOTE  0.994711   0.299645   \n",
            "4  Brain Class  RFC  oversample  RandomOverSampler  0.994537   0.292894   \n",
            "8  Brain Class  RFC  oversample             ADASYN  0.994068   0.276144   \n",
            "\n",
            "   F1_score       AUC  \n",
            "0  0.603306  0.999961  \n",
            "6  0.463649  0.998955  \n",
            "5  0.461119  0.998966  \n",
            "4  0.453083  0.999731  \n",
            "8  0.432778  0.998729  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, roc_auc_score, f1_score\n",
        "\n",
        "# 1. Load dataset\n",
        "df = pd.read_csv('class.csv', low_memory=False)\n",
        "df.info()\n",
        "\n",
        "# Check missing data\n",
        "for col in df.columns:\n",
        "    missing_data = df[col].isna().sum()\n",
        "    if missing_data > 0:\n",
        "        print(f\"Column {col} has {missing_data} missing values\")\n",
        "\n",
        "# 2. Define Features & Target\n",
        "features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "target = 'Brain Class'\n",
        "\n",
        "if target not in df.columns:\n",
        "    raise ValueError(\"Target column 'Brain Class' not found in dataset!\")\n",
        "\n",
        "df[target] = df[target].astype(int)  # Ensure target is integer\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# 3. Split Dataset into Training, Validation, and Testing Sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# 4. Balance the Training Set using Undersampling (Different Ratios)\n",
        "ratios = {\n",
        "    \"90:10\": 9.0,\n",
        "    \"80:20\": 4.0,\n",
        "    \"75:25\": 3.0,\n",
        "    \"60:40\": 1.5,\n",
        "    \"50:50\": 1.0\n",
        "}\n",
        "\n",
        "balanced_datasets = {}\n",
        "for ratio_name, ratio in ratios.items():\n",
        "    undersampler = RandomUnderSampler(sampling_strategy=1/ratio, random_state=42)\n",
        "    X_train_bal, y_train_bal = undersampler.fit_resample(X_train, y_train)\n",
        "    balanced_datasets[ratio_name] = (X_train_bal, y_train_bal)\n",
        "\n",
        "# 5. Train & Evaluate Models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "def train_and_test(model, model_name, X_train, y_train, X_test, y_test, ratio_name):\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    predictions = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_test)\n",
        "    pred_labels = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, pred_labels)\n",
        "    precision = precision_score(y_test, pred_labels, average='binary')\n",
        "    f1 = f1_score(y_test, pred_labels, average='binary')\n",
        "    roc_auc = roc_auc_score(y_test, predictions)\n",
        "\n",
        "    print(f\"\\n🚀 {model_name} (Balance: {ratio_name})\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "    print(classification_report(y_test, pred_labels))\n",
        "\n",
        "    results.append({\n",
        "        \"Code_smell\": target,\n",
        "        \"Algo\": model_name,\n",
        "        \"Balance\": ratio_name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"F1_score\": f1,\n",
        "        \"AUC\": roc_auc\n",
        "    })\n",
        "\n",
        "# 6. Run Experiments with Different Models & Balance Ratios\n",
        "for ratio_name, (X_train_bal, y_train_bal) in balanced_datasets.items():\n",
        "    for model_name, model in models.items():\n",
        "        train_and_test(model, model_name, X_train_bal, y_train_bal, X_test, y_test, ratio_name)\n",
        "\n",
        "# 7. Save Results to CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"brain_class_results1.csv\", index=False)\n",
        "print(\"\\n✅ Results saved to 'brain_class_results.csv'!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em_-l9b51FEK",
        "outputId": "94e2e060-3155-47d3-c13c-ac4e470c5660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 373400 entries, 0 to 373399\n",
            "Data columns (total 50 columns):\n",
            " #   Column                    Non-Null Count   Dtype  \n",
            "---  ------                    --------------   -----  \n",
            " 0   Address                   373400 non-null  object \n",
            " 1   Brain Class               373400 non-null  bool   \n",
            " 2   Data Class                373400 non-null  bool   \n",
            " 3   Futile Abstract Pipeline  373400 non-null  bool   \n",
            " 4   Futile Hierarchy          373400 non-null  bool   \n",
            " 5   God Class                 373400 non-null  bool   \n",
            " 6   Hierarchy Duplication     373400 non-null  bool   \n",
            " 7   Model Class               373400 non-null  bool   \n",
            " 8   Schizofrenic Class        373400 non-null  bool   \n",
            " 9   ABUSEINH                  373400 non-null  int64  \n",
            " 10  AMW                       373400 non-null  float64\n",
            " 11  ATFD                      373400 non-null  int64  \n",
            " 12  BOvM                      373400 non-null  int64  \n",
            " 13  BUR                       373400 non-null  float64\n",
            " 14  CBO                       373400 non-null  int64  \n",
            " 15  CC                        373400 non-null  int64  \n",
            " 16  CM                        373400 non-null  int64  \n",
            " 17  CRIX                      373400 non-null  float64\n",
            " 18  DAC                       373400 non-null  int64  \n",
            " 19  DIT                       373400 non-null  int64  \n",
            " 20  EDUPCLS                   373400 non-null  int64  \n",
            " 21  FANOUT                    373400 non-null  int64  \n",
            " 22  FDP                       373400 non-null  int64  \n",
            " 23  GREEDY                    373400 non-null  int64  \n",
            " 24  HDUPCLS                   373400 non-null  int64  \n",
            " 25  HIT                       373400 non-null  int64  \n",
            " 26  IDUPLINES                 373400 non-null  int64  \n",
            " 27  LOCC                      373400 non-null  int64  \n",
            " 28  NAS                       373400 non-null  int64  \n",
            " 29  NAbsM                     373400 non-null  int64  \n",
            " 30  NDU                       373400 non-null  int64  \n",
            " 31  NOA                       373400 non-null  int64  \n",
            " 32  NOAM                      373400 non-null  int64  \n",
            " 33  NOD                       373400 non-null  int64  \n",
            " 34  NODD                      373400 non-null  int64  \n",
            " 35  NOM                       373400 non-null  int64  \n",
            " 36  NOPA                      373400 non-null  int64  \n",
            " 37  NProtM                    373400 non-null  int64  \n",
            " 38  NSPECM                    373400 non-null  int64  \n",
            " 39  NTempF                    373400 non-null  int64  \n",
            " 40  NrBM                      373400 non-null  int64  \n",
            " 41  NrEC                      373400 non-null  int64  \n",
            " 42  NrFE                      373400 non-null  int64  \n",
            " 43  NrIC                      373400 non-null  int64  \n",
            " 44  NrSS                      373400 non-null  int64  \n",
            " 45  PNAS                      373400 non-null  float64\n",
            " 46  SCHIZO                    373400 non-null  int64  \n",
            " 47  TCC                       373400 non-null  float64\n",
            " 48  WMC                       373400 non-null  int64  \n",
            " 49  WOC                       373400 non-null  float64\n",
            "dtypes: bool(8), float64(6), int64(35), object(1)\n",
            "memory usage: 122.5+ MB\n",
            "\n",
            "🚀 Random Forest (Balance: 90:10)\n",
            "Accuracy: 0.9968\n",
            "Precision: 0.4091\n",
            "F1 Score: 0.5806\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.41      1.00      0.58       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.70      1.00      0.79     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Logistic Regression (Balance: 90:10)\n",
            "Accuracy: 0.9935\n",
            "Precision: 0.2516\n",
            "F1 Score: 0.3980\n",
            "ROC AUC: 0.9976\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     55884\n",
            "           1       0.25      0.95      0.40       126\n",
            "\n",
            "    accuracy                           0.99     56010\n",
            "   macro avg       0.63      0.97      0.70     56010\n",
            "weighted avg       1.00      0.99      1.00     56010\n",
            "\n",
            "\n",
            "🚀 SVM (Balance: 90:10)\n",
            "Accuracy: 0.9804\n",
            "Precision: 0.0859\n",
            "F1 Score: 0.1551\n",
            "ROC AUC: 0.9896\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     55884\n",
            "           1       0.09      0.80      0.16       126\n",
            "\n",
            "    accuracy                           0.98     56010\n",
            "   macro avg       0.54      0.89      0.57     56010\n",
            "weighted avg       1.00      0.98      0.99     56010\n",
            "\n",
            "\n",
            "🚀 KNN (Balance: 90:10)\n",
            "Accuracy: 0.9802\n",
            "Precision: 0.0966\n",
            "F1 Score: 0.1752\n",
            "ROC AUC: 0.9884\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     55884\n",
            "           1       0.10      0.94      0.18       126\n",
            "\n",
            "    accuracy                           0.98     56010\n",
            "   macro avg       0.55      0.96      0.58     56010\n",
            "weighted avg       1.00      0.98      0.99     56010\n",
            "\n",
            "\n",
            "🚀 Decision Tree (Balance: 90:10)\n",
            "Accuracy: 0.9993\n",
            "Precision: 0.7683\n",
            "F1 Score: 0.8690\n",
            "ROC AUC: 0.9997\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.77      1.00      0.87       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.88      1.00      0.93     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Naive Bayes (Balance: 90:10)\n",
            "Accuracy: 0.9614\n",
            "Precision: 0.0547\n",
            "F1 Score: 0.1036\n",
            "ROC AUC: 0.9787\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     55884\n",
            "           1       0.05      0.99      0.10       126\n",
            "\n",
            "    accuracy                           0.96     56010\n",
            "   macro avg       0.53      0.98      0.54     56010\n",
            "weighted avg       1.00      0.96      0.98     56010\n",
            "\n",
            "\n",
            "🚀 Gradient Boosting (Balance: 90:10)\n",
            "Accuracy: 0.9998\n",
            "Precision: 0.9197\n",
            "F1 Score: 0.9582\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.92      1.00      0.96       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.96      1.00      0.98     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 AdaBoost (Balance: 90:10)\n",
            "Accuracy: 0.9993\n",
            "Precision: 0.7590\n",
            "F1 Score: 0.8630\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.76      1.00      0.86       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.88      1.00      0.93     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Random Forest (Balance: 80:20)\n",
            "Accuracy: 0.9952\n",
            "Precision: 0.3206\n",
            "F1 Score: 0.4855\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.32      1.00      0.49       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.66      1.00      0.74     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Logistic Regression (Balance: 80:20)\n",
            "Accuracy: 0.9903\n",
            "Precision: 0.1861\n",
            "F1 Score: 0.3126\n",
            "ROC AUC: 0.9972\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     55884\n",
            "           1       0.19      0.98      0.31       126\n",
            "\n",
            "    accuracy                           0.99     56010\n",
            "   macro avg       0.59      0.98      0.65     56010\n",
            "weighted avg       1.00      0.99      0.99     56010\n",
            "\n",
            "\n",
            "🚀 SVM (Balance: 80:20)\n",
            "Accuracy: 0.9731\n",
            "Precision: 0.0710\n",
            "F1 Score: 0.1316\n",
            "ROC AUC: 0.9884\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     55884\n",
            "           1       0.07      0.90      0.13       126\n",
            "\n",
            "    accuracy                           0.97     56010\n",
            "   macro avg       0.54      0.94      0.56     56010\n",
            "weighted avg       1.00      0.97      0.98     56010\n",
            "\n",
            "\n",
            "🚀 KNN (Balance: 80:20)\n",
            "Accuracy: 0.9706\n",
            "Precision: 0.0696\n",
            "F1 Score: 0.1299\n",
            "ROC AUC: 0.9862\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     55884\n",
            "           1       0.07      0.98      0.13       126\n",
            "\n",
            "    accuracy                           0.97     56010\n",
            "   macro avg       0.53      0.97      0.56     56010\n",
            "weighted avg       1.00      0.97      0.98     56010\n",
            "\n",
            "\n",
            "🚀 Decision Tree (Balance: 80:20)\n",
            "Accuracy: 0.9989\n",
            "Precision: 0.6667\n",
            "F1 Score: 0.8000\n",
            "ROC AUC: 0.9994\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.67      1.00      0.80       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.83      1.00      0.90     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Naive Bayes (Balance: 80:20)\n",
            "Accuracy: 0.9621\n",
            "Precision: 0.0556\n",
            "F1 Score: 0.1054\n",
            "ROC AUC: 0.9850\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     55884\n",
            "           1       0.06      0.99      0.11       126\n",
            "\n",
            "    accuracy                           0.96     56010\n",
            "   macro avg       0.53      0.98      0.54     56010\n",
            "weighted avg       1.00      0.96      0.98     56010\n",
            "\n",
            "\n",
            "🚀 Gradient Boosting (Balance: 80:20)\n",
            "Accuracy: 0.9997\n",
            "Precision: 0.8690\n",
            "F1 Score: 0.9299\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.87      1.00      0.93       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.93      1.00      0.96     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 AdaBoost (Balance: 80:20)\n",
            "Accuracy: 0.9983\n",
            "Precision: 0.5625\n",
            "F1 Score: 0.7200\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.56      1.00      0.72       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.78      1.00      0.86     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Random Forest (Balance: 75:25)\n",
            "Accuracy: 0.9950\n",
            "Precision: 0.3119\n",
            "F1 Score: 0.4755\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.31      1.00      0.48       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.66      1.00      0.74     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Logistic Regression (Balance: 75:25)\n",
            "Accuracy: 0.9899\n",
            "Precision: 0.1793\n",
            "F1 Score: 0.3030\n",
            "ROC AUC: 0.9970\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     55884\n",
            "           1       0.18      0.98      0.30       126\n",
            "\n",
            "    accuracy                           0.99     56010\n",
            "   macro avg       0.59      0.98      0.65     56010\n",
            "weighted avg       1.00      0.99      0.99     56010\n",
            "\n",
            "\n",
            "🚀 SVM (Balance: 75:25)\n",
            "Accuracy: 0.9705\n",
            "Precision: 0.0655\n",
            "F1 Score: 0.1221\n",
            "ROC AUC: 0.9880\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     55884\n",
            "           1       0.07      0.91      0.12       126\n",
            "\n",
            "    accuracy                           0.97     56010\n",
            "   macro avg       0.53      0.94      0.55     56010\n",
            "weighted avg       1.00      0.97      0.98     56010\n",
            "\n",
            "\n",
            "🚀 KNN (Balance: 75:25)\n",
            "Accuracy: 0.9681\n",
            "Precision: 0.0644\n",
            "F1 Score: 0.1209\n",
            "ROC AUC: 0.9854\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     55884\n",
            "           1       0.06      0.98      0.12       126\n",
            "\n",
            "    accuracy                           0.97     56010\n",
            "   macro avg       0.53      0.97      0.55     56010\n",
            "weighted avg       1.00      0.97      0.98     56010\n",
            "\n",
            "\n",
            "🚀 Decision Tree (Balance: 75:25)\n",
            "Accuracy: 0.9970\n",
            "Precision: 0.4315\n",
            "F1 Score: 0.6029\n",
            "ROC AUC: 0.9985\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.43      1.00      0.60       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.72      1.00      0.80     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Naive Bayes (Balance: 75:25)\n",
            "Accuracy: 0.9620\n",
            "Precision: 0.0551\n",
            "F1 Score: 0.1044\n",
            "ROC AUC: 0.9841\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     55884\n",
            "           1       0.06      0.98      0.10       126\n",
            "\n",
            "    accuracy                           0.96     56010\n",
            "   macro avg       0.53      0.97      0.54     56010\n",
            "weighted avg       1.00      0.96      0.98     56010\n",
            "\n",
            "\n",
            "🚀 Gradient Boosting (Balance: 75:25)\n",
            "Accuracy: 0.9995\n",
            "Precision: 0.8289\n",
            "F1 Score: 0.9065\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.83      1.00      0.91       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.91      1.00      0.95     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 AdaBoost (Balance: 75:25)\n",
            "Accuracy: 0.9985\n",
            "Precision: 0.6058\n",
            "F1 Score: 0.7545\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.61      1.00      0.75       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.80      1.00      0.88     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Random Forest (Balance: 60:40)\n",
            "Accuracy: 0.9940\n",
            "Precision: 0.2716\n",
            "F1 Score: 0.4271\n",
            "ROC AUC: 0.9997\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     55884\n",
            "           1       0.27      1.00      0.43       126\n",
            "\n",
            "    accuracy                           0.99     56010\n",
            "   macro avg       0.64      1.00      0.71     56010\n",
            "weighted avg       1.00      0.99      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Logistic Regression (Balance: 60:40)\n",
            "Accuracy: 0.9868\n",
            "Precision: 0.1452\n",
            "F1 Score: 0.2533\n",
            "ROC AUC: 0.9964\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     55884\n",
            "           1       0.15      0.99      0.25       126\n",
            "\n",
            "    accuracy                           0.99     56010\n",
            "   macro avg       0.57      0.99      0.62     56010\n",
            "weighted avg       1.00      0.99      0.99     56010\n",
            "\n",
            "\n",
            "🚀 SVM (Balance: 60:40)\n",
            "Accuracy: 0.9616\n",
            "Precision: 0.0521\n",
            "F1 Score: 0.0988\n",
            "ROC AUC: 0.9878\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     55884\n",
            "           1       0.05      0.94      0.10       126\n",
            "\n",
            "    accuracy                           0.96     56010\n",
            "   macro avg       0.53      0.95      0.54     56010\n",
            "weighted avg       1.00      0.96      0.98     56010\n",
            "\n",
            "\n",
            "🚀 KNN (Balance: 60:40)\n",
            "Accuracy: 0.9611\n",
            "Precision: 0.0547\n",
            "F1 Score: 0.1038\n",
            "ROC AUC: 0.9868\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     55884\n",
            "           1       0.05      1.00      0.10       126\n",
            "\n",
            "    accuracy                           0.96     56010\n",
            "   macro avg       0.53      0.98      0.54     56010\n",
            "weighted avg       1.00      0.96      0.98     56010\n",
            "\n",
            "\n",
            "🚀 Decision Tree (Balance: 60:40)\n",
            "Accuracy: 0.9985\n",
            "Precision: 0.6029\n",
            "F1 Score: 0.7522\n",
            "ROC AUC: 0.9993\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.60      1.00      0.75       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.80      1.00      0.88     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Naive Bayes (Balance: 60:40)\n",
            "Accuracy: 0.9596\n",
            "Precision: 0.0482\n",
            "F1 Score: 0.0916\n",
            "ROC AUC: 0.9795\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     55884\n",
            "           1       0.05      0.90      0.09       126\n",
            "\n",
            "    accuracy                           0.96     56010\n",
            "   macro avg       0.52      0.93      0.54     56010\n",
            "weighted avg       1.00      0.96      0.98     56010\n",
            "\n",
            "\n",
            "🚀 Gradient Boosting (Balance: 60:40)\n",
            "Accuracy: 0.9985\n",
            "Precision: 0.6029\n",
            "F1 Score: 0.7522\n",
            "ROC AUC: 0.9996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.60      1.00      0.75       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.80      1.00      0.88     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 AdaBoost (Balance: 60:40)\n",
            "Accuracy: 0.9982\n",
            "Precision: 0.5551\n",
            "F1 Score: 0.7139\n",
            "ROC AUC: 0.9999\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.56      1.00      0.71       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.78      1.00      0.86     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Random Forest (Balance: 50:50)\n",
            "Accuracy: 0.9945\n",
            "Precision: 0.2890\n",
            "F1 Score: 0.4484\n",
            "ROC AUC: 0.9998\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     55884\n",
            "           1       0.29      1.00      0.45       126\n",
            "\n",
            "    accuracy                           0.99     56010\n",
            "   macro avg       0.64      1.00      0.72     56010\n",
            "weighted avg       1.00      0.99      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Logistic Regression (Balance: 50:50)\n",
            "Accuracy: 0.9840\n",
            "Precision: 0.1216\n",
            "F1 Score: 0.2164\n",
            "ROC AUC: 0.9960\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     55884\n",
            "           1       0.12      0.98      0.22       126\n",
            "\n",
            "    accuracy                           0.98     56010\n",
            "   macro avg       0.56      0.98      0.60     56010\n",
            "weighted avg       1.00      0.98      0.99     56010\n",
            "\n",
            "\n",
            "🚀 SVM (Balance: 50:50)\n",
            "Accuracy: 0.9578\n",
            "Precision: 0.0485\n",
            "F1 Score: 0.0923\n",
            "ROC AUC: 0.9877\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     55884\n",
            "           1       0.05      0.95      0.09       126\n",
            "\n",
            "    accuracy                           0.96     56010\n",
            "   macro avg       0.52      0.96      0.54     56010\n",
            "weighted avg       1.00      0.96      0.98     56010\n",
            "\n",
            "\n",
            "🚀 KNN (Balance: 50:50)\n",
            "Accuracy: 0.9540\n",
            "Precision: 0.0466\n",
            "F1 Score: 0.0891\n",
            "ROC AUC: 0.9866\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98     55884\n",
            "           1       0.05      1.00      0.09       126\n",
            "\n",
            "    accuracy                           0.95     56010\n",
            "   macro avg       0.52      0.98      0.53     56010\n",
            "weighted avg       1.00      0.95      0.97     56010\n",
            "\n",
            "\n",
            "🚀 Decision Tree (Balance: 50:50)\n",
            "Accuracy: 0.9963\n",
            "Precision: 0.3761\n",
            "F1 Score: 0.5466\n",
            "ROC AUC: 0.9981\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.38      1.00      0.55       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.69      1.00      0.77     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 Naive Bayes (Balance: 50:50)\n",
            "Accuracy: 0.9598\n",
            "Precision: 0.0481\n",
            "F1 Score: 0.0912\n",
            "ROC AUC: 0.9794\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     55884\n",
            "           1       0.05      0.90      0.09       126\n",
            "\n",
            "    accuracy                           0.96     56010\n",
            "   macro avg       0.52      0.93      0.54     56010\n",
            "weighted avg       1.00      0.96      0.98     56010\n",
            "\n",
            "\n",
            "🚀 Gradient Boosting (Balance: 50:50)\n",
            "Accuracy: 0.9985\n",
            "Precision: 0.6000\n",
            "F1 Score: 0.7500\n",
            "ROC AUC: 0.9997\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.60      1.00      0.75       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.80      1.00      0.87     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "🚀 AdaBoost (Balance: 50:50)\n",
            "Accuracy: 0.9973\n",
            "Precision: 0.4516\n",
            "F1 Score: 0.6222\n",
            "ROC AUC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55884\n",
            "           1       0.45      1.00      0.62       126\n",
            "\n",
            "    accuracy                           1.00     56010\n",
            "   macro avg       0.73      1.00      0.81     56010\n",
            "weighted avg       1.00      1.00      1.00     56010\n",
            "\n",
            "\n",
            "✅ Results saved to 'brain_class_results.csv'!\n"
          ]
        }
      ]
    }
  ]
}